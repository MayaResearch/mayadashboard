---
title: Database Query Best Practices
description: Senior Engineer guidelines for writing efficient, optimized database queries with minimal round-trips
tags: [database, sql, queries, optimization, performance]
alwaysApply: true
---

# Database Query Best Practices

## üéØ Core Principle: Minimize Query Count

**ALWAYS aim to fetch all required data in the fewest possible queries.** Every database round-trip adds latency. Think in terms of "how can I get everything I need in ONE query" before writing code.

---

## ‚ö° The N+1 Query Problem

### ‚ùå NEVER Do This

```typescript
// N+1 Problem: 1 query for users + N queries for orders
const users = await db.query('SELECT * FROM users');

for (const user of users) {
  // This runs N times! BAD!
  const orders = await db.query('SELECT * FROM orders WHERE user_id = ?', [user.id]);
  user.orders = orders;
}
```

### ‚úÖ ALWAYS Do This

```typescript
// Single query with JOIN - gets everything at once
const usersWithOrders = await db.query(`
  SELECT u.*, o.id as order_id, o.total, o.created_at as order_date
  FROM users u
  LEFT JOIN orders o ON u.id = o.user_id
  WHERE u.active = true
`);

// Or use batch loading if you need separate queries
const users = await db.query('SELECT * FROM users WHERE active = true');
const userIds = users.map(u => u.id);

// ONE query for all orders instead of N queries
const orders = await db.query(
  'SELECT * FROM orders WHERE user_id IN (?)',
  [userIds]
);
```

---

## üîÑ Query Batching & Consolidation

### Batch Multiple Lookups

```typescript
// ‚ùå BAD: Multiple separate queries
const user = await db.query('SELECT * FROM users WHERE id = ?', [userId]);
const settings = await db.query('SELECT * FROM settings WHERE user_id = ?', [userId]);
const preferences = await db.query('SELECT * FROM preferences WHERE user_id = ?', [userId]);

// ‚úÖ GOOD: Single query with JOINs
const result = await db.query(`
  SELECT 
    u.*,
    s.theme, s.language, s.notifications,
    p.email_frequency, p.timezone
  FROM users u
  LEFT JOIN settings s ON u.id = s.user_id
  LEFT JOIN preferences p ON u.id = p.user_id
  WHERE u.id = ?
`, [userId]);
```

### Use CTEs for Complex Queries

```sql
-- ‚úÖ Common Table Expressions keep queries readable and efficient
WITH user_stats AS (
  SELECT 
    user_id,
    COUNT(*) as order_count,
    SUM(total) as total_spent
  FROM orders
  WHERE created_at > NOW() - INTERVAL '30 days'
  GROUP BY user_id
),
recent_activity AS (
  SELECT 
    user_id,
    MAX(created_at) as last_activity
  FROM user_events
  GROUP BY user_id
)
SELECT 
  u.id, u.name, u.email,
  COALESCE(us.order_count, 0) as order_count,
  COALESCE(us.total_spent, 0) as total_spent,
  ra.last_activity
FROM users u
LEFT JOIN user_stats us ON u.id = us.user_id
LEFT JOIN recent_activity ra ON u.id = ra.user_id
WHERE u.active = true;
```

---

## üìã SELECT Only What You Need

### ‚ùå NEVER Use SELECT *

```typescript
// ‚ùå BAD: Fetches ALL columns including blobs, timestamps you don't need
const users = await db.query('SELECT * FROM users');

// ‚ùå BAD: Even worse with JOINs - duplicate columns, wasted bandwidth
const data = await db.query('SELECT * FROM users u JOIN orders o ON u.id = o.user_id');
```

### ‚úÖ Explicitly List Required Columns

```typescript
// ‚úÖ GOOD: Only fetch what you need
const users = await db.query(`
  SELECT id, name, email, avatar_url
  FROM users
  WHERE active = true
`);

// ‚úÖ GOOD: Use aliases for clarity in JOINs
const data = await db.query(`
  SELECT 
    u.id as user_id,
    u.name as user_name,
    o.id as order_id,
    o.total as order_total
  FROM users u
  JOIN orders o ON u.id = o.user_id
`);
```

---

## üìÑ Pagination Done Right

### ‚ùå NEVER Load All Records

```typescript
// ‚ùå TERRIBLE: Loads entire table into memory
const allUsers = await db.query('SELECT * FROM users');
const pageUsers = allUsers.slice(offset, offset + limit);

// ‚ùå BAD: OFFSET-based pagination is slow for large datasets
const users = await db.query(`
  SELECT * FROM users
  ORDER BY created_at DESC
  OFFSET 100000 LIMIT 20
`); // This scans 100,020 rows!
```

### ‚úÖ Use Cursor-Based Pagination

```typescript
// ‚úÖ GOOD: Cursor-based (keyset) pagination - consistent performance
const users = await db.query(`
  SELECT id, name, email, created_at
  FROM users
  WHERE created_at < ? AND id < ?
  ORDER BY created_at DESC, id DESC
  LIMIT 20
`, [lastCreatedAt, lastId]);

// For API response
return {
  data: users,
  cursor: users.length > 0 ? {
    created_at: users[users.length - 1].created_at,
    id: users[users.length - 1].id
  } : null
};
```

---

## üîç Indexing Strategy

### Index What You Query

```sql
-- ‚úÖ Create indexes for frequently queried columns
CREATE INDEX idx_users_email ON users(email);
CREATE INDEX idx_users_active ON users(active);
CREATE INDEX idx_orders_user_id ON orders(user_id);

-- ‚úÖ Composite indexes for common query patterns
-- Order matters! Most selective column first
CREATE INDEX idx_orders_user_status_date ON orders(user_id, status, created_at);

-- ‚úÖ Partial indexes for specific queries
CREATE INDEX idx_active_users ON users(email) WHERE active = true;

-- ‚úÖ Covering indexes to avoid table lookups
CREATE INDEX idx_users_lookup ON users(id) INCLUDE (name, email);
```

### Always Check Query Plans

```sql
-- ‚úÖ ALWAYS use EXPLAIN before deploying queries
EXPLAIN ANALYZE SELECT * FROM users WHERE email = 'test@example.com';

-- Look for:
-- - Index scans (good) vs Sequential scans (bad for large tables)
-- - Nested loops with high row counts (bad)
-- - Sort operations (consider adding index)
```

---

## üõ°Ô∏è SQL Injection Prevention

### ‚ùå NEVER Concatenate User Input

```typescript
// ‚ùå CRITICAL SECURITY VULNERABILITY!
const query = `SELECT * FROM users WHERE email = '${userInput}'`;

// ‚ùå ALSO BAD: Template literals
const query = `SELECT * FROM users WHERE id = ${id}`;
```

### ‚úÖ ALWAYS Use Parameterized Queries

```typescript
// ‚úÖ SAFE: Parameterized queries
const user = await db.query(
  'SELECT * FROM users WHERE email = ?',
  [userInput]
);

// ‚úÖ SAFE: Named parameters (if supported)
const user = await db.query(
  'SELECT * FROM users WHERE email = :email AND active = :active',
  { email: userInput, active: true }
);

// ‚úÖ SAFE: Query builders handle escaping
const users = await knex('users')
  .where('email', userInput)
  .andWhere('active', true);
```

---

## üì¶ Transactions

### Use Transactions for Related Operations

```typescript
// ‚úÖ GOOD: Atomic operations with transactions
const client = await pool.connect();
try {
  await client.query('BEGIN');
  
  const user = await client.query(
    'INSERT INTO users (name, email) VALUES ($1, $2) RETURNING id',
    [name, email]
  );
  
  await client.query(
    'INSERT INTO user_settings (user_id, theme) VALUES ($1, $2)',
    [user.rows[0].id, 'dark']
  );
  
  await client.query(
    'INSERT INTO audit_log (action, user_id) VALUES ($1, $2)',
    ['user_created', user.rows[0].id]
  );
  
  await client.query('COMMIT');
  return user.rows[0];
} catch (error) {
  await client.query('ROLLBACK');
  throw error;
} finally {
  client.release();
}
```

---

## üèÉ Performance Optimizations

### Use EXISTS Instead of COUNT

```typescript
// ‚ùå SLOW: COUNT scans all matching rows
const result = await db.query(`
  SELECT COUNT(*) > 0 as has_orders
  FROM orders
  WHERE user_id = ?
`, [userId]);

// ‚úÖ FAST: EXISTS stops at first match
const result = await db.query(`
  SELECT EXISTS(
    SELECT 1 FROM orders WHERE user_id = ?
  ) as has_orders
`, [userId]);
```

### Use LIMIT for Existence Checks

```typescript
// ‚úÖ GOOD: Stop searching after finding one
const order = await db.query(`
  SELECT id FROM orders
  WHERE user_id = ? AND status = 'pending'
  LIMIT 1
`, [userId]);

const hasPendingOrders = order.length > 0;
```

### Batch Inserts/Updates

```typescript
// ‚ùå BAD: N separate INSERT statements
for (const item of items) {
  await db.query('INSERT INTO items (name, price) VALUES (?, ?)', [item.name, item.price]);
}

// ‚úÖ GOOD: Single bulk INSERT
const values = items.map(item => [item.name, item.price]);
await db.query(`
  INSERT INTO items (name, price)
  VALUES ?
`, [values]);

// ‚úÖ GOOD: Using UNNEST for PostgreSQL
await db.query(`
  INSERT INTO items (name, price)
  SELECT * FROM UNNEST($1::text[], $2::decimal[])
`, [names, prices]);
```

### Use UPSERT for Insert-or-Update

```sql
-- ‚úÖ PostgreSQL: ON CONFLICT
INSERT INTO user_settings (user_id, theme, updated_at)
VALUES ($1, $2, NOW())
ON CONFLICT (user_id)
DO UPDATE SET theme = EXCLUDED.theme, updated_at = NOW();

-- ‚úÖ MySQL: ON DUPLICATE KEY
INSERT INTO user_settings (user_id, theme, updated_at)
VALUES (?, ?, NOW())
ON DUPLICATE KEY UPDATE theme = VALUES(theme), updated_at = NOW();
```

---

## üóÑÔ∏è Connection Management

### Use Connection Pooling

```typescript
// ‚úÖ GOOD: Configure connection pool
const pool = new Pool({
  host: process.env.DB_HOST,
  database: process.env.DB_NAME,
  max: 20,                    // Maximum connections
  min: 5,                     // Minimum connections
  idleTimeoutMillis: 30000,   // Close idle connections after 30s
  connectionTimeoutMillis: 2000, // Fail fast if can't connect
});

// ‚úÖ GOOD: Always release connections
async function executeQuery(sql: string, params: any[]): Promise<any> {
  const client = await pool.connect();
  try {
    return await client.query(sql, params);
  } finally {
    client.release(); // ALWAYS release!
  }
}
```

---

## üíæ Caching Strategy

### Cache Frequently Accessed Data

```typescript
// ‚úÖ GOOD: Cache with invalidation strategy
async function getUserById(id: string): Promise<User> {
  const cacheKey = `user:${id}`;
  
  // Check cache first
  const cached = await cache.get(cacheKey);
  if (cached) {
    return JSON.parse(cached);
  }
  
  // Query database
  const user = await db.query('SELECT * FROM users WHERE id = ?', [id]);
  
  // Cache with TTL
  await cache.setex(cacheKey, 3600, JSON.stringify(user));
  
  return user;
}

// ‚úÖ Invalidate on updates
async function updateUser(id: string, data: Partial<User>): Promise<void> {
  await db.query('UPDATE users SET ... WHERE id = ?', [...values, id]);
  await cache.del(`user:${id}`); // Invalidate cache
}
```

### Use Database-Level Caching

```sql
-- ‚úÖ PostgreSQL: Materialized views for complex queries
CREATE MATERIALIZED VIEW user_order_stats AS
SELECT 
  user_id,
  COUNT(*) as total_orders,
  SUM(total) as lifetime_value,
  MAX(created_at) as last_order_date
FROM orders
GROUP BY user_id;

-- Refresh periodically
REFRESH MATERIALIZED VIEW CONCURRENTLY user_order_stats;
```

---

## üìä Query Monitoring & Debugging

### Log Slow Queries

```typescript
// ‚úÖ Wrap queries with timing
async function queryWithLogging<T>(
  sql: string, 
  params: any[], 
  threshold = 100 // ms
): Promise<T> {
  const start = Date.now();
  const result = await db.query(sql, params);
  const duration = Date.now() - start;
  
  if (duration > threshold) {
    console.warn(`üêå Slow Query (${duration}ms):`, {
      sql: sql.substring(0, 200),
      params,
      duration
    });
  }
  
  return result;
}
```

### Enable Database Query Logging

```sql
-- ‚úÖ PostgreSQL: Log slow queries
ALTER SYSTEM SET log_min_duration_statement = 100; -- Log queries > 100ms
SELECT pg_reload_conf();

-- ‚úÖ Check for missing indexes
SELECT 
  schemaname, tablename, 
  seq_scan, idx_scan,
  seq_tup_read, idx_tup_fetch
FROM pg_stat_user_tables
WHERE seq_scan > idx_scan
ORDER BY seq_tup_read DESC;
```

---

## üß™ ORM Best Practices

### Eager Loading with ORMs

```typescript
// ‚ùå BAD: Lazy loading causes N+1
const users = await User.findAll();
for (const user of users) {
  console.log(user.orders); // N additional queries!
}

// ‚úÖ GOOD: Eager loading
const users = await User.findAll({
  include: [
    { model: Order, as: 'orders' },
    { model: Profile, as: 'profile' }
  ]
});

// ‚úÖ GOOD: Prisma with include
const users = await prisma.user.findMany({
  include: {
    orders: true,
    profile: true
  }
});

// ‚úÖ GOOD: Use select to limit fields
const users = await prisma.user.findMany({
  select: {
    id: true,
    name: true,
    email: true,
    orders: {
      select: { id: true, total: true }
    }
  }
});
```

---

## üìã Query Optimization Checklist

Before every database query, verify:

- [ ] **Minimized query count** - Can this be combined with another query?
- [ ] **SELECT specific columns** - No `SELECT *`
- [ ] **Proper JOINs** - Using appropriate JOIN types
- [ ] **Parameterized** - No string concatenation
- [ ] **Indexed columns** - WHERE/JOIN columns are indexed
- [ ] **Pagination** - Using cursor-based for large datasets
- [ ] **LIMIT applied** - Not fetching more than needed
- [ ] **EXPLAIN analyzed** - Query plan reviewed for production queries
- [ ] **Caching considered** - Frequently accessed data cached
- [ ] **Transaction used** - Related writes are atomic
- [ ] **Connection released** - Pool connections properly managed
- [ ] **N+1 prevented** - No queries inside loops

---

## üö® Red Flags to Watch For

| Pattern | Problem | Solution |
|---------|---------|----------|
| Query in a loop | N+1 queries | Batch with IN clause or JOIN |
| `SELECT *` | Wasted bandwidth | Select specific columns |
| `OFFSET` pagination | Slow on large datasets | Cursor-based pagination |
| String concatenation | SQL injection | Parameterized queries |
| No indexes on WHERE | Full table scans | Add appropriate indexes |
| Unbounded queries | Memory overflow | Always use LIMIT |
| Lazy loading | Hidden N+1 | Eager loading with include |
| No EXPLAIN | Unknown performance | Analyze all production queries |

---

## üí° Senior Engineer Mindset

1. **Think in sets, not loops** - SQL operates on sets; embrace it
2. **Measure before optimizing** - Use EXPLAIN, profiling, logs
3. **Design for scale** - What works for 100 rows may fail at 1M
4. **Index strategically** - Over-indexing hurts writes
5. **Cache intelligently** - Know your read/write ratios
6. **Fail gracefully** - Handle connection failures, timeouts
7. **Monitor continuously** - Set up slow query alerts
8. **Document complex queries** - Future you will thank present you
